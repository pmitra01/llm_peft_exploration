{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce2a79b",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87d886",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "do you want to use collate_fn in data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d4826-da4a-4baa-a01d-11cd6fce8ab1",
   "metadata": {},
   "source": [
    "### imports and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_SMALL = \"t5-small\"\n",
    "GPT = \"gpt2\"  # 117M parameters as per https://huggingface.co/transformers/v3.3.1/pretrained_models.html # \"openai-gpt\"\n",
    "DISTILBERT = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db5d391-db12-4559-8a75-4fb68d5b144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "from collections import defaultdict\n",
    "\n",
    "# mandatory imports\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data import random_split\n",
    "import collections\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48dffa1a-8f35-4ffa-8b88-4b9675cdceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SIZE = 0.1\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "METRIC_NAME = \"f1\"\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192c31b-3784-4d6c-a200-c5f535e60f28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16035507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/jovyan/llm_peft_exploration/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4109fbd0124b4c709609b89cffcf4668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#raw_dataset = load_dataset('super_glue', 'cb', cache_dir=\"./datasets/.cache/huggingface_datasets\")\n",
    "raw_dataset = load_dataset('ag_news', cache_dir=\"./datasets/.cache/huggingface_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba172029",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "\n",
    "label2id = {v:k for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4a67c-21ad-4062-9907-7292e79eab13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01e1cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 120000, 'test': 7600}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(raw_dataset[k]) for k in raw_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431d804b-af29-4409-bcbc-c84ee122cef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6eca9-97ff-45ec-8465-a5b8ee66b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15927ee5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b37d9ca-7147-44fe-a8d3-ae92e0c7d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(GPT)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'  # 'left'\n",
    "\n",
    "# Use `DataCollatorWithPadding` as it is more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding to max length\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89b3edcb-52c3-45e9-a9a5-aaed829f43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"text\"]  # this has n_rows which = batch_size\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "    # add labels\n",
    "    labels_batch = torch.tensor(examples['label'])\n",
    "    #torch.transpose(labels_batch, 0, 1)\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = torch.nn.functional.one_hot(labels_batch)\n",
    "    labels_matrix = labels_matrix.float()  # without converting int to float, you get an error later\n",
    "    # print(labels_matrix)\n",
    "    encoding[\"label\"] = labels_matrix#.tolist()\n",
    "  \n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fcb5b-3d12-49dd-b740-eda501eff7e3",
   "metadata": {},
   "source": [
    "#### encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c981946-cb3c-4b3b-8937-a47cb3f2d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize \n",
    "#encoded_dataset = raw_dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6da82525-414e-4c12-86b1-2face6f8c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(ds, tokenizer, create_validation_split=False, validation_prop=0.1):\n",
    "    encoded_dataset = ds.map(preprocess_data, batched=True)\n",
    "    # is this needed?\n",
    "    encoded_dataset.set_format(\"torch\")\n",
    "    \n",
    "    # we need to create tratin/valid sets\n",
    "    print(f\"creating validation split: {str(create_validation_split)}\")\n",
    "    if create_validation_split:\n",
    "        train_dataset, validation_dataset= encoded_dataset['train'].train_test_split(test_size=validation_prop).values()\n",
    "    return {'train': train_dataset, 'valid': validation_dataset, 'test': ds['test']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f7efee-44ed-4b7d-9da3-01275a080666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_label_distr_from_data_loader(dl):\n",
    "    label_list = []\n",
    "    for idx, item in enumerate(dl):\n",
    "        batch_labels_onehot = item['label']#.tolist()\n",
    "        batch_labels = [torch.argmax(label_onehot).item() for label_onehot in batch_labels_onehot]\n",
    "        label_list.extend(batch_labels)\n",
    "    print(f'distribution of labels: {collections.Counter(label_list)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83d66476-be35-4313-8e49-ddb3e57759ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/llm_peft_exploration/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-7e91ac84989644cd.arrow\n",
      "Loading cached processed dataset at /home/jovyan/llm_peft_exploration/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-9439a82d3c544e5b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating validation split: True\n",
      "distribution of labels: Counter({2: 3028, 3: 3001, 0: 2998, 1: 2973})\n",
      "distribution of labels: Counter({1: 27027, 0: 27002, 3: 26999, 2: 26972})\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = prepare_dataset(raw_dataset, tokenizer, create_validation_split=True)\n",
    "valid_loader = DataLoader(encoded_dataset['valid'], batch_size=BATCH_SIZE, shuffle=True)#, collate_fn=data_collator)\n",
    "train_loader = DataLoader(encoded_dataset['train'], batch_size=BATCH_SIZE, shuffle=True)#, collate_fn=data_collator)\n",
    "\n",
    "describe_label_distr_from_data_loader(valid_loader)\n",
    "describe_label_distr_from_data_loader(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff102e16-a3f4-4254-b5d8-3be11316cd25",
   "metadata": {},
   "source": [
    "### tokenise, training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d297ff8-8a79-4c71-b80d-6d7e3c5acb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(f\"data/models_20230606\")\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2ca45be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(GPT, \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(label2id),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dfe326c-3ade-418f-b8e4-782ae6e24281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eed688-0c7d-405e-9ded-a43d0ecb7175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f03676-1dde-4145-8000-fe1033adf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f17e5c7e-e91f-4785-aba2-fe9064e408da",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=0.1,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=METRIC_NAME,\n",
    "    logging_dir='./logs',            # directory for storing logs*\n",
    "    logging_steps=2000,\n",
    "    report_to='wandb'\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11d963b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=batch_dataset,\n",
    "    eval_dataset=encoded_dataset['valid'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de9b1cfc-6f13-4830-8666-f4d080443ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "505e44f8-ae75-4635-8018-46526c3068b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpmitra01\u001b[0m (\u001b[33mdiscoverylab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/llm_peft_exploration/wandb/run-20230606_195044-4mu1g9g2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/discoverylab/huggingface/runs/4mu1g9g2' target=\"_blank\">unique-oath-8</a></strong> to <a href='https://wandb.ai/discoverylab/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/discoverylab/huggingface' target=\"_blank\">https://wandb.ai/discoverylab/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/discoverylab/huggingface/runs/4mu1g9g2' target=\"_blank\">https://wandb.ai/discoverylab/huggingface/runs/4mu1g9g2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 36/375 04:38 < 45:01, 0.13 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677d24c-070d-45da-8176-34778dbfe5cd",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "732fa338-df65-4127-bb5f-fe85be3f4373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0778539851307869,\n",
       " 'eval_f1': 0.9458218549127639,\n",
       " 'eval_roc_auc': 0.9633611111111112,\n",
       " 'eval_accuracy': 0.9409166666666666}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26ee8ebe-86f8-4187-87ef-c632a44e6be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08296191692352295,\n",
       " 'eval_f1': 0.9416106497957031,\n",
       " 'eval_roc_auc': 0.9605701754385965,\n",
       " 'eval_accuracy': 0.9361842105263158}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.eval_dataset=encoded_dataset['test']\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0abb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(prompt_model, 'data/models/tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c0717",
   "metadata": {},
   "source": [
    "test how the accuracy improves with batches of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fcc855-871d-474a-a013-d2fc74fe5a96",
   "metadata": {},
   "source": [
    "### experiment - sequential supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96b7381d-3cdb-42a7-8c04-1b1b0adecd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import BatchSampler, SequentialSampler, DataLoader\n",
    "list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b033068b-a4fe-4ecb-a990-b722201b9510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 108000\n",
      "}), 'indices': [0, 1, 2]}\n",
      "{'dataset': Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 108000\n",
      "}), 'indices': [0, 1, 2, 3, 4, 5]}\n",
      "{'dataset': Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 108000\n",
      "}), 'indices': [0, 1, 2, 3, 4, 5, 6, 7, 8]}\n",
      "{'dataset': Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 108000\n",
      "}), 'indices': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7fdc905c29d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do for 10, 50, 100, 1000, 20000, 100000\n",
    "from torch.utils.data import Subset\n",
    "total_subset_idx = []\n",
    "sequential_supervision_val_scores = []\n",
    "sequential_supervision_test_scores = []\n",
    "for idx, idx_batch in enumerate(BatchSampler(SequentialSampler(range(len(encoded_dataset['train']))), batch_size=3, drop_last=False)):\n",
    "    if idx<4:\n",
    "        total_subset_idx.extend(idx_batch)\n",
    "        batch_dataset = Subset(encoded_dataset['train'], total_subset_idx)\n",
    "        #batch_loader = DataLoader(batch_dataset)\n",
    "\n",
    "        #print(batch_dataset)\n",
    "        #print(batch_dataset.indices)\n",
    "        \n",
    "        trainer = Trainer(\n",
    "                    model,\n",
    "                    args,\n",
    "                    train_dataset=batch_dataset,\n",
    "                    eval_dataset=encoded_dataset['valid'],\n",
    "                    tokenizer=tokenizer,\n",
    "                    compute_metrics=compute_metrics,\n",
    "                    #data_collator=data_collator\n",
    "                )\n",
    "        trainer.train()\n",
    "        val_scores = trainer.evaluate()        \n",
    "        sequential_supervision_val_scores.append(val_scores)\n",
    "        \n",
    "        trainer.eval_dataset=encoded_dataset['test']\n",
    "        test_scores = trainer.evaluate()\n",
    "        sequential_supervision_val_scores.append(test_scores)\n",
    "\n",
    "        \n",
    "        \n",
    "        #trainer.save()\n",
    "batch_dataset                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea50482-b74f-4174-9cfd-bc7320aeb6db",
   "metadata": {},
   "source": [
    "##### push model to hf hub\n",
    "\n",
    "(https://colab.research.google.com/drive/1U7SX7jNYsNQG5BY1xEQQHu48Pn6Vgnyt?usp=sharing#scrollTo=H5j5YJE2hK58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5544d343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5ee05875f940e8af9d802355ad8d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"your-username/model-name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-bioblp-env [Python]",
   "language": "python",
   "name": "conda-env-.conda-bioblp-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
