{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce2a79b",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87d886",
   "metadata": {},
   "source": [
    "Text classification is a common NLP task that assigns a label or class to text. Some of the largest companies run text classification in production for a wide range of practical applications. One of the most popular forms of text classification is sentiment analysis, which assigns a label like üôÇ positive, üôÅ negative, or üòê neutral to a sequence of text.\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "1. Finetune [DistilBERT](https://huggingface.co/distilbert-base-uncased) on the [IMDb](https://huggingface.co/datasets/imdb) dataset to determine whether a movie review is positive or negative.\n",
    "2. Use your finetuned model for inference.\n",
    "\n",
    "<Tip>\n",
    "The task illustrated in this tutorial is supported by the following model architectures:\n",
    "\n",
    "<!--This tip is automatically generated by `make fix-copies`, do not fill manually!-->\n",
    "\n",
    "[ALBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/albert), [BART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bart), [BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bert), [BigBird](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/big_bird), [BigBird-Pegasus](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bigbird_pegasus), [BLOOM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/bloom), [CamemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/camembert), [CANINE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/canine), [ConvBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/convbert), [CTRL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ctrl), [Data2VecText](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/data2vec-text), [DeBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta), [DeBERTa-v2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/deberta-v2), [DistilBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/distilbert), [ELECTRA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/electra), [ERNIE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie), [ErnieM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ernie_m), [ESM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/esm), [FlauBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/flaubert), [FNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/fnet), [Funnel Transformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/funnel), [GPT-Sw3](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt-sw3), [OpenAI GPT-2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt2), [GPTBigCode](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_bigcode), [GPT Neo](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neo), [GPT NeoX](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gpt_neox), [GPT-J](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/gptj), [I-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/ibert), [LayoutLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlm), [LayoutLMv2](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv2), [LayoutLMv3](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/layoutlmv3), [LED](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/led), [LiLT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/lilt), [LLaMA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/llama), [Longformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/longformer), [LUKE](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/luke), [MarkupLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/markuplm), [mBART](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mbart), [MEGA](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mega), [Megatron-BERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/megatron-bert), [MobileBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mobilebert), [MPNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mpnet), [MVP](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/mvp), [Nezha](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nezha), [Nystr√∂mformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/nystromformer), [OpenAI GPT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/openai-gpt), [OPT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/opt), [Perceiver](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/perceiver), [PLBart](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/plbart), [QDQBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/qdqbert), [Reformer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/reformer), [RemBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/rembert), [RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta), [RoBERTa-PreLayerNorm](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roberta-prelayernorm), [RoCBert](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roc_bert), [RoFormer](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/roformer), [SqueezeBERT](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/squeezebert), [TAPAS](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/tapas), [Transformer-XL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/transfo-xl), [XLM](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm), [XLM-RoBERTa](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta), [XLM-RoBERTa-XL](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlm-roberta-xl), [XLNet](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xlnet), [X-MOD](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/xmod), [YOSO](https://huggingface.co/docs/transformers/main/en/tasks/../model_doc/yoso)\n",
    "\n",
    "\n",
    "<!--End of the generated tip-->\n",
    "\n",
    "</Tip>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e773f31",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15927ee5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess\n",
    "- load DistilBERT Tokenizer to process the text field\n",
    "Can we load T5-small?\n",
    "- Create a preprocessinging function to tokenize text and trucnate sequences to be no longer than DistilBERT's or T5's max input length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_SMALL = \"t5-small\"\n",
    "GPT = \"gpt2\"  # 117M parameters as per https://huggingface.co/transformers/v3.3.1/pretrained_models.html # \"openai-gpt\"\n",
    "DISTILBERT = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5185a208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(GPT)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0734652b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imdb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_function\u001b[39m(examples):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m tokenized_imdb \u001b[38;5;241m=\u001b[39m \u001b[43mimdb\u001b[49m\u001b[38;5;241m.\u001b[39mmap(preprocess_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Use `DataCollatorWithPadding` as it is more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding to max length\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imdb' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)\n",
    "\n",
    "# Use `DataCollatorWithPadding` as it is more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding to max length\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0c1a2",
   "metadata": {},
   "source": [
    "## openprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "from collections import defaultdict\n",
    "\n",
    "# mandatory imports\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ace758",
   "metadata": {
    "tags": []
   },
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16035507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/jovyan/llm_peft_exploration/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  4.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#raw_dataset = load_dataset('super_glue', 'cb', cache_dir=\"./datasets/.cache/huggingface_datasets\")\n",
    "raw_dataset = load_dataset('ag_news', cache_dir=\"./datasets/.cache/huggingface_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01e1cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 120000, 'test': 7600}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(raw_dataset[k]) for k in raw_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c184cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label_distr(data_split):\n",
    "    label_distr = defaultdict(list)\n",
    "    for idx, item in enumerate(raw_dataset[data_split]):\n",
    "        label = item['label']\n",
    "        label_distr[item['label']].append(idx)\n",
    "    label_distr_lens = {label: len(label_distr[label]) for label in label_distr.keys()}\n",
    "    print(f\"label distribution in {data_split} is:\\n{label_distr_lens}\")\n",
    "    return label_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acc05da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution in train is:\n",
      "{2: 30000, 3: 30000, 1: 30000, 0: 30000}\n"
     ]
    }
   ],
   "source": [
    "DATA_SPLIT = 'train'\n",
    "train_label_distr = check_label_distr(data_split=DATA_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81d699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution in test is:\n",
      "{2: 1900, 3: 1900, 1: 1900, 0: 1900}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_SPLIT = 'test'\n",
    "CLASS_LABEL = 2\n",
    "test_label_distr = check_label_distr(data_split=DATA_SPLIT)\n",
    "raw_dataset[DATA_SPLIT][test_label_distr[CLASS_LABEL][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16176cf5",
   "metadata": {},
   "source": [
    "Cast examples into openprompts's InputExample structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9847892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"guid\": 0,\n",
      "  \"label\": 2,\n",
      "  \"meta\": {},\n",
      "  \"text_a\": \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
      "  \"text_b\": \"\",\n",
      "  \"tgt_text\": null\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "dataset = {}\n",
    "for split in ['train', 'test']:\n",
    "    dataset[split] = []\n",
    "    for idx, data in enumerate(raw_dataset[split]):\n",
    "        input_example = InputExample(text_a = data['text'], label=int(data['label']), guid=idx)\n",
    "        dataset[split].append(input_example)\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf5ab6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openprompt.plms import load_plm\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm('t5', 't5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c66541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing Template\n",
    "# A template can be constructed from the yaml config, but it can also be constructed by directly passing arguments.\n",
    "from openprompt.prompts import ManualTemplate\n",
    "template_text = '{\"placeholder\":\"text_a\"}. The topic of this news headline is {\"mask\"}.'\n",
    "mytemplate = ManualTemplate(tokenizer=tokenizer, text=template_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c38d74c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'text': \"Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market next week during the depth of the  summer doldrums.\", 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '. The topic of this news headline is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '.', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 10, 'label': 2}]\n"
     ]
    }
   ],
   "source": [
    "# To better understand how does the template wrap the example, we visualize one instance.\n",
    "wrapped_example = mytemplate.wrap_one_example(dataset['train'][10])\n",
    "print(wrapped_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba172029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7fb4d07",
   "metadata": {},
   "source": [
    "* Now the wrapped example is ready to be passed to the tokenizer, hence producing the input for the language model\n",
    "* You can use the tokenizer to tokenize the input yourelf but we recommend using the wrapped tokenizer, which is wrapped around the tokenizer tailored for the InputExample\n",
    "* The wrapper has been given if you use our `load_plm` function, otherwise you shoudl choose the suitable wrapper based on the configs in `openprompt.plms.__init__.py`\n",
    "* Note that when t5 is used for classification, we only need to pass `<pad><extra_id_0><eos>` to decoder.\n",
    "* the loss is calculated at the `<extra_id_0>`. Thus passing decder_max_length=3 saves the space\n",
    "(`<extra_id_0>` is the `<mask>` token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa55c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_t5tokenizer = WrapperClass(max_seq_length=256, decoder_max_length=3, tokenizer=tokenizer,truncate_method=\"head\")\n",
    "# or\n",
    "#from openprompt.plms import T5TokenizerWrapper\n",
    "#wrapped_t5tokenizer= T5TokenizerWrapper(max_seq_length=128, decoder_max_length=3, tokenizer=tokenizer,truncate_method=\"head\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dfc39e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [6067, 11, 22077, 5713, 6394, 7, 31, 19269, 8747, 3, 476, 2990, 439, 41, 18844, 61, 3, 18, 180, 26605, 19058, 1596, 303, 17168, 81, 8, 2717, 11, 8, 16395, 21, 8783, 33, 1644, 12, 5168, 147, 8, 1519, 512, 416, 471, 383, 8, 4963, 13, 8, 1248, 103, 40, 17870, 7, 5, 3, 5, 37, 2859, 13, 48, 1506, 12392, 19, 32099, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'decoder_input_ids': [0, 32099, 0], 'loss_ids': [0, 1, 0]}\n",
      "['‚ñÅOil', '‚ñÅand', '‚ñÅEconomy', '‚ñÅCloud', '‚ñÅStock', 's', \"'\", '‚ñÅOutlook', '‚ñÅNEW', '‚ñÅ', 'Y', 'OR', 'K', '‚ñÅ(', 'Reuters', ')', '‚ñÅ', '-', '‚ñÅS', 'oaring', '‚ñÅcrude', '‚ñÅprices', '‚ñÅplus', '‚ñÅworries', '‚ñÅabout', '‚ñÅthe', '‚ñÅeconomy', '‚ñÅand', '‚ñÅthe', '‚ñÅoutlook', '‚ñÅfor', '‚ñÅearnings', '‚ñÅare', '‚ñÅexpected', '‚ñÅto', '‚ñÅhang', '‚ñÅover', '‚ñÅthe', '‚ñÅstock', '‚ñÅmarket', '‚ñÅnext', '‚ñÅweek', '‚ñÅduring', '‚ñÅthe', '‚ñÅdepth', '‚ñÅof', '‚ñÅthe', '‚ñÅsummer', '‚ñÅdo', 'l', 'drum', 's', '.', '‚ñÅ', '.', '‚ñÅThe', '‚ñÅtopic', '‚ñÅof', '‚ñÅthis', '‚ñÅnews', '‚ñÅheadline', '‚ñÅis', '<extra_id_0>', '‚ñÅ', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<pad>', '<extra_id_0>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "# You can see what a tokenized example looks like by\n",
    "tokenized_example = wrapped_t5tokenizer.tokenize_one_example(wrapped_example, teacher_forcing=False)\n",
    "print(tokenized_example)\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_example['input_ids']))\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_example['decoder_input_ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bcce8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's time to convert the whole dataset into the input format!\n",
    "# Simply loop over the dataset to achieve it!\n",
    "\n",
    "model_inputs = {}\n",
    "for split in ['test']:  # ['train', 'test']:\n",
    "    model_inputs[split] = []\n",
    "    for sample in dataset[split]:\n",
    "        tokenized_example = wrapped_t5tokenizer.tokenize_one_example(mytemplate.wrap_one_example(sample), teacher_forcing=False)\n",
    "        model_inputs[split].append(tokenized_example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dde937e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 120000it [02:51, 698.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# We provide a `PromptDataLoader` class to help you do all the above matters and wrap them into an `torch.DataLoader` style iterator.\n",
    "from openprompt import PromptDataLoader\n",
    "\n",
    "train_dataloader = PromptDataLoader(dataset=dataset[\"train\"], template=mytemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=256, decoder_max_length=3,\n",
    "    batch_size=16,shuffle=True, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")\n",
    "# next(iter(train_dataloader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69412f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['world', 'sports', 'business', 'sci/tech']\n",
    "id2label_dict = {idx:k for idx, k in enumerate(classes)}\n",
    "label2id_dict = {v:k for k,v in id2label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "127f5f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[  296,     0],\n",
      "         [    0,     0],\n",
      "         [    0,     0]],\n",
      "\n",
      "        [[ 2100,     0],\n",
      "         [    0,     0],\n",
      "         [    0,     0]],\n",
      "\n",
      "        [[  268,     0],\n",
      "         [    0,     0],\n",
      "         [    0,     0]],\n",
      "\n",
      "        [[ 2056,     0],\n",
      "         [  748,     0],\n",
      "         [17201,  5256]]])\n"
     ]
    }
   ],
   "source": [
    "# Define the verbalizer\n",
    "# In classification, you need to define your verbalizer, which is a mapping from logits on the vocabulary to the final label probability. Let's have a look at the verbalizer details:\n",
    "\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "import torch\n",
    "\n",
    "# for example the verbalizer contains multiple label words in each class\n",
    "myverbalizer = ManualVerbalizer(\n",
    "    tokenizer,\n",
    "    num_classes=4,\n",
    "    classes=classes,\n",
    "    label_words={\n",
    "        \"world\": [\"world\"],\n",
    "        \"sports\": [\"sports\"],\n",
    "        \"business\": [\"business\"],\n",
    "        \"sci/tech\": [\"science\",  \"technology\", \"sci tech\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(myverbalizer.label_words_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916d4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(tokenizer) returns the vocab_size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "150a7c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1145, -2.4590, -0.9576, -2.2278],\n",
      "        [-1.9564, -2.5508, -1.5859, -1.7017]])\n"
     ]
    }
   ],
   "source": [
    "logits = torch.randn(2,len(tokenizer)) # creating a pseudo output from the plm, and\n",
    "print(myverbalizer.process_logits(logits)) # see what the verbalizer does\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ed414",
   "metadata": {},
   "source": [
    "Although you can manually combine the plm, template, verbalizer together, we provide a pipeline\n",
    "model which takes the batched data from the PromptDataLoader and produces class wise logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e84c8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt import PromptForClassification\n",
    "\n",
    "use_cuda = True\n",
    "prompt_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n",
    "if use_cuda:\n",
    "    prompt_model=  prompt_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0f37ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the training is standard\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# it's always good practice to set no decay to biase and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2ca45be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e780af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 7600it [00:10, 705.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=256, decoder_max_length=3,\n",
    "    batch_size=4,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11d963b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b46a11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<38:03,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 0.07447695569135249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:54<27:37,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 0.09317532743272194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:49<17:07,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 0.09629840620888583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:43<07:14,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 0.09757871261904678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:07<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: test accuracy: 0.9465789473684211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:45,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average loss: 0.031372164376080036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<27:28,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average loss: 0.03638204309497708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:48<17:10,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average loss: 0.041061164024217466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:40<07:23,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average loss: 0.042727474881904176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:05<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test accuracy: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:40,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, average loss: 0.008110608905553818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<26:58,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, average loss: 0.019265413387238885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:46<17:05,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, average loss: 0.023106005005659007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:39<07:35,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, average loss: 0.025498516863532664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:04<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: test accuracy: 0.9465789473684211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:47,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, average loss: 0.0018224656232632697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<27:27,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, average loss: 0.01433275319054617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:47<17:25,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, average loss: 0.017226989501110814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:41<07:29,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, average loss: 0.01908128715847471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:06<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: test accuracy: 0.9464473684210526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<42:51,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, average loss: 0.0010925912647508085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<26:43,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, average loss: 0.012275348992028971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:47<17:08,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, average loss: 0.01310150157845624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:39<07:19,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, average loss: 0.015475986897156149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:04<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: test accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<38:04,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, average loss: 0.00480890175094828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:54<27:04,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, average loss: 0.011649178321212029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:47<17:21,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, average loss: 0.01214325343143492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:39<07:23,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, average loss: 0.013850588207033502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:04<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: test accuracy: 0.9472368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:30,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, average loss: 0.0001773704971128609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<26:55,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, average loss: 0.010855463469311162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:47<17:16,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, average loss: 0.012064546242813825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:42<07:37,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, average loss: 0.01250786911575898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:07<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: test accuracy: 0.9478947368421052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:23,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, average loss: 0.0009870353387668729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:54<27:15,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, average loss: 0.007647645044765501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:51<17:45,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, average loss: 0.009735594871383875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:48<07:24,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, average loss: 0.01019961646487118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:14<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: test accuracy: 0.9456578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<38:35,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, average loss: 0.0006434436654672027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:55<26:44,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, average loss: 0.010980361509342151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:49<16:58,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, average loss: 0.010838185029570315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:44<07:25,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, average loss: 0.010895906623017877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:10<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: test accuracy: 0.9447368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:47,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, average loss: 0.010528070370128262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:54<27:06,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, average loss: 0.009318949781246576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:48<17:20,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, average loss: 0.010102476102322058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:43<07:30,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, average loss: 0.011255457109534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:07<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: test accuracy: 0.9467105263157894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:16,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, average loss: 8.784360215940978e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:54<26:58,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, average loss: 0.006546116735990147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:48<18:20,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, average loss: 0.008889513546248137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:40<07:17,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, average loss: 0.009827858608230659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:04<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: test accuracy: 0.9469736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:23,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, average loss: 0.0011608727218117565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<26:50,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, average loss: 0.006660266698941149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:47<16:56,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, average loss: 0.008020238391335437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5336/7500 [26:22<10:28,  3.44it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:48<17:10,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, average loss: 0.007884605233659463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5012/7500 [24:48<12:08,  3.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:55<26:57,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, average loss: 0.008033443022561813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:50<17:30,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, average loss: 0.008259694514089342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:45<07:27,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, average loss: 0.008924862471027702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:11<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: test accuracy: 0.9478947368421052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:28,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, average loss: 0.00048300328489858657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<27:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, average loss: 0.005861840679875735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:49<17:17,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, average loss: 0.006774755869287761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:41<07:39,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, average loss: 0.0071073428124988425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:09<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: test accuracy: 0.9486842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<38:16,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, average loss: 0.01741854052670533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:52<26:55,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, average loss: 0.006390110117993448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:46<16:59,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, average loss: 0.0067789925776595445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:39<07:21,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, average loss: 0.007404725531324859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:04<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: test accuracy: 0.9481578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:41,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, average loss: 0.0008547779070795514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:53<27:28,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, average loss: 0.005855757648435902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:47<17:38,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, average loss: 0.007172257324654123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:39<07:21,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, average loss: 0.007530230293921482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [37:01<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: test accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<41:02,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, average loss: 4.2787789425347e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:51<27:10,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, average loss: 0.004507046333325917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:43<17:23,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, average loss: 0.0058147416288691365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:34<07:18,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, average loss: 0.006744115019564166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [36:59<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: test accuracy: 0.9477631578947369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<37:34,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, average loss: 5.784257382401847e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:52<26:44,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, average loss: 0.004421349419179631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:43<17:12,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, average loss: 0.004974599751183542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:34<07:44,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, average loss: 0.005956028616079698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [36:58<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: test accuracy: 0.9457894736842105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7500 [00:00<40:03,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, average loss: 0.002635062555782497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 2001/7500 [09:51<26:46,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, average loss: 0.004935971168553347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4001/7500 [19:44<17:18,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, average loss: 0.004854086502257933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6001/7500 [29:35<07:29,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, average loss: 0.006098550923006531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [36:58<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: test accuracy: 0.9463157894736842\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "use_cuda = True\n",
    "for epoch in range(20):\n",
    "    tot_loss = 0\n",
    "    for step, inputs in enumerate(tqdm(train_dataloader)):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        labels = inputs['label']\n",
    "        loss = loss_func(logits, labels)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        ep_train_loss = tot_loss/(step+1)\n",
    "        if step %2000 ==1:\n",
    "            train_losses.append(ep_train_loss)\n",
    "            print(\"Epoch {}, average loss: {}\".format(epoch, ep_train_loss), flush=True)\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "    for batch, inputs in enumerate(test_dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        labels = inputs['label']\n",
    "        alllabels.extend(labels.cpu().tolist())\n",
    "        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "    acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "    print(f'Epoch {epoch}: test accuracy: {acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0abb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(prompt_model, 'data/models/tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c0717",
   "metadata": {},
   "source": [
    "test how the accuracy improves with batches of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4d52a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('test_losses.json', 'w+') as f:\n",
    "    json.dump(test_losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1fe70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('train_losses.json', 'w+') as f:\n",
    "    json.dump(test_losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffccee51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9107142857142857"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpreds = []\n",
    "alllabels = []\n",
    "for batch, inputs in enumerate(validation_dataloader):\n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda()\n",
    "    logits = prompt_model(inputs)\n",
    "    labels = inputs['label']\n",
    "    alllabels.extend(labels.cpu().tolist())\n",
    "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "acc    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b79650",
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b105ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=alllabels, y_pred=allpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb0708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-bioblp-env [Python]",
   "language": "python",
   "name": "conda-env-.conda-bioblp-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
