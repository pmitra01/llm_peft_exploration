{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855e41be",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa38d9a",
   "metadata": {},
   "source": [
    "### imports and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd15279",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_SMALL = \"t5-small\"\n",
    "GPT = \"gpt2\"  # 117M parameters as per https://huggingface.co/transformers/v3.3.1/pretrained_models.html # \"openai-gpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23c2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "from collections import defaultdict\n",
    "\n",
    "# mandatory imports\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data import random_split\n",
    "import collections\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd1f8a",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0ca06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SIZE = 0.1\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "METRIC_NAME = \"f1\"\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe400f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f65f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/jovyan/llm_peft_exploration/notebooks/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74344b6cfcb8430985909264bc1ae63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#raw_dataset = load_dataset('super_glue', 'cb', cache_dir=\"./datasets/.cache/huggingface_datasets\")\n",
    "raw_dataset = load_dataset('ag_news', cache_dir=\"./datasets/.cache/huggingface_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1feb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "\n",
    "label2id = {v:k for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecb262",
   "metadata": {
    "tags": []
   },
   "source": [
    "### explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b300ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 120000, 'test': 7600}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(raw_dataset[k]) for k in raw_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2e2e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test'][0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d167b344",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49214d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(GPT)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'  # 'left'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cefc9c1f-f656-4518-9c7b-4268804a9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 384\n",
    "stride = 128\n",
    "\n",
    "max_input_length = 364\n",
    "max_target_length = 32\n",
    "\n",
    "\n",
    "prefix1 = \"Given news article: \"\n",
    "prefix2 = \"The news article topic is: \"\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    context = [prefix1 + doc for doc in examples[\"text\"] ]\n",
    "    #topics = [prefix2 + q.strip() for q in examples[\"label\"]]\n",
    "    topic_labels = [id2label[q] for q in examples[\"label\"]]\n",
    "    prepped_topics = [prefix2+ topic for topic in topic_labels]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        context,\n",
    "        prepped_topics,\n",
    "        max_length=max_input_length,\n",
    "        truncation=\"only_first\",\n",
    "        #stride=stride,\n",
    "        #return_overflowing_tokens=True,\n",
    "        #return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def preprocess_test_data(examples):\n",
    "    context = [prefix1 + doc + prefix2 for doc in examples[\"text\"] ]\n",
    "    topic_labels = [id2label[q] for q in examples[\"label\"]]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        context,\n",
    "    )\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
    "    inputs[\"answer\"] = topic_labels\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100c87d6-f6dd-4190-8175-8776abebc891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/llm_peft_exploration/notebooks/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-7250863f9cba77a0.arrow\n"
     ]
    }
   ],
   "source": [
    "test_dataset = raw_dataset['test'].map(preprocess_test_data, batched=True, batch_size=BATCH_SIZE, remove_columns=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd71622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given news article: Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.The news article topic is: \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[0]['labels'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1ea71",
   "metadata": {},
   "source": [
    "#### encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae3a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(ds, tokenizer, create_validation_split=False, validation_prop=0.1, remove_columns=[]):\n",
    "    train_dataset = ds['train'].map(preprocess_data, batched=True, remove_columns=remove_columns)\n",
    "    test_dataset = ds['test'].map(preprocess_test_data, batched=True, remove_columns=remove_columns)\n",
    "\n",
    "    train_dataset.set_format(\"torch\")\n",
    "    validation_dataset = None\n",
    "    # carve out validation set from train\n",
    "    print(f\"creating validation split: {str(create_validation_split)}\")\n",
    "    if create_validation_split:\n",
    "        # had forgotten to add random split earlier during the seq training exercise\n",
    "        train_dataset, validation_dataset= train_dataset.train_test_split(test_size=validation_prop).values()\n",
    "    return {'train': train_dataset, 'valid': validation_dataset, 'test': test_dataset}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff36b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/llm_peft_exploration/notebooks/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-6a1730659d4cc655.arrow\n",
      "Loading cached processed dataset at /home/jovyan/llm_peft_exploration/notebooks/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-b2b255dbd88aa3a1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating validation split: True\n"
     ]
    }
   ],
   "source": [
    "# tokenize \n",
    "encoded_dataset = prepare_dataset(raw_dataset, tokenizer, create_validation_split=True,  remove_columns=[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de553ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given news article: Sri Lanka beat Pakistan in Faisalabad Test (AFP) AFP - Sri Lanka defeated Pakistan by 201 runs in the first cricket Test here to take a 1-0 lead in the two-match series.The news article topic is: World \n",
      "\n",
      "Given news article: Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.The news article topic is:  \n",
      "\n",
      "Given news article: Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.The news article topic is: \n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(encoded_dataset['train'][2]['input_ids'], skip_special_tokens=True), '\\n')\n",
    "\n",
    "# we have intentionally not padded test sentences\n",
    "print(tokenizer.decode(encoded_dataset['test'][2]['input_ids'], skip_special_tokens=True), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ff5e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tokenise, training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "491ce9a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(f\"data/models_20230806\")\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc5aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(GPT, \n",
    "problem_type=\"multi_label_classification_with_generative_lm\")\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d7834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d8eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SIZE = 0.1\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "METRIC_NAME = \"f1\"\n",
    "N_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd013b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir='./logs',            # directory for storing logs*\n",
    "    logging_steps=2000,\n",
    "    report_to='wandb',\n",
    "    save_total_limit = 5,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0afcfd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['valid'],\n",
    "    tokenizer=tokenizer,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a6187730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11505, 18121, 12914,  3517, 15069, 40136, 24087,  1883,   287, 20357,\n",
       "           383,  3517,  2732,   329,  7868,   290, 20389,   357,    35,    69,\n",
       "          1546,     8,  2904,  5611,   257,   366, 22648, 36757,    78,     1,\n",
       "          1923,    11,   351,   262, 23619, 27339,  6778,   286, 36267,   262,\n",
       "          1306,  5270,   286,  3517, 17245,    13,  8989,    11,   484,   635,\n",
       "         31230,   510,   351,   262,  2647,  2831,   357,  3620,    40,    11,\n",
       "           290,  2972,  7912,     8,   284,   787,   428,  2968,    13,   412,\n",
       "          8895,   468,  5729, 22368,   511,   886,   880,    11,   523,   326,\n",
       "          1751,   287,   674,  4266,   481,   783,   307, 41201,  3898,   546,\n",
       "           262,  4416,  1483,   286, 22023,  2647,    13,   464, 17010,   290,\n",
       "          2709,  4355,   286,   428,  1392,   284,   502,   257,  1310,    11,\n",
       "           523,   314,  2630,   281,  1280,  3850,   284,   262,   360,    69,\n",
       "          1546,   546,   340,    13,  8989,    11,   340,   338,  7190,  5109,\n",
       "            11,   355,   314, 11691,   345,   423,   284,   307,   618,  3597,\n",
       "           284,   467,   332,   434, 10826,    13,   887,   314,  2911,   345,\n",
       "          1064,   340,  4465,    11,   290,  3737,  1254,  7867,   284,   466,\n",
       "          1223,  2092,    11,   611,   393,   618,   262,   976,  1517,   468,\n",
       "          3022,   287,   534,  1989,    13,   464,  3850,  2925]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=3, do_sample=True, top_k=5, eos_token_id=model.config.eos_token_id\n",
    ")\n",
    "out = model.generate(**inputs, generation_config=generation_config)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b69d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "187e2eee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### define trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a53706",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_pts = 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6b211b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "id2label_dict = {idx:k for idx, k in enumerate(classes)}\n",
    "label2id_dict = {v:k for k,v in id2label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb09873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1855fec4",
   "metadata": {},
   "source": [
    "### Experiment: Sequential training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d548f",
   "metadata": {},
   "source": [
    "test how the accuracy improves with batches of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a66946",
   "metadata": {},
   "source": [
    "https://www.scottcondron.com/jupyter/visualisation/audio/2020/12/02/dataloaders-samplers-collate.html#Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a223999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from torch.utils.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "712013e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 10\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bc3b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import SequentialTrainingBatchSampler\n",
    "BASE=10\n",
    "\n",
    "custom_sequential_sampler = SequentialTrainingBatchSampler(encoded_dataset['train'], batch_size=-1, base=BASE)\n",
    "for i, batch in enumerate(custom_sequential_sampler):\n",
    "    print(f\"Batch number #{i}:  {batch}\")\n",
    "    if i>=1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe340b-774e-4dcd-9dad-5578142b52e4",
   "metadata": {},
   "source": [
    "### check cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8485c320-cf39-4ff2-919a-b929b9c186e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do for 10, 50, 100, 1000, 20000, 100000\n",
    "MODEL_DIR = Path(f\"data/models_20230807\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0997f6e-2782-4e95-be59-fce29a8b2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_series_with_sequential_sampler(batch_size=BATCH_SIZE, n_epochs=5,\n",
    "                                              compute_metrics: Callable = None, output_model_dir=MODEL_DIR_NEW, \n",
    "                                               learning_rate=LEARNING_RATE, metric_name=METRIC_NAME):\n",
    "    total_subset_idx = []\n",
    "    sequential_supervision_val_scores = []\n",
    "    sequential_supervision_test_scores = []\n",
    "    for idx, idx_batch in enumerate(custom_sequential_sampler):\n",
    "        print(idx)\n",
    "        if idx>4:\n",
    "            break\n",
    "        sequence_n_output_dir = output_model_dir.joinpath(f\"_{idx}\")\n",
    "        batch_dataset = Subset(encoded_dataset['train'], idx_batch)\n",
    "        print(f\"Number of training data points: {len(idx_batch)}\")\n",
    "        args = TrainingArguments(\n",
    "            output_dir=sequence_n_output_dir,\n",
    "            evaluation_strategy=\"steps\", #epoch\",\n",
    "            eval_steps = 500,\n",
    "            save_strategy=\"steps\", #epoch\",\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=n_epochs,\n",
    "            weight_decay=0.01,\n",
    "            metric_for_best_model=metric_name,\n",
    "            logging_dir='./logs',            # directory for storing logs*\n",
    "            logging_steps=2000,\n",
    "            # report_to='wandb',\n",
    "            load_best_model_at_end = True,\n",
    "            save_total_limit = 2,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "                    model,\n",
    "                    args,\n",
    "                    train_dataset=batch_dataset,\n",
    "                    eval_dataset=encoded_dataset['valid'],\n",
    "                    tokenizer=tokenizer,\n",
    "                    compute_metrics=compute_metrics,\n",
    "            #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "                    #data_collator=data_collator\n",
    "                )\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "        print(f\"evaluating on test set\")\n",
    "        trainer.eval_dataset=encoded_dataset['test']\n",
    "        test_scores = trainer.evaluate()\n",
    "        sequential_supervision_test_scores.append(test_scores)\n",
    "        #trainer.save()\n",
    "\n",
    "\n",
    "        print(f\"evaluating on validation set\")\n",
    "        trainer.eval_dataset=encoded_dataset['valid']\n",
    "        val_scores = trainer.evaluate()        \n",
    "        sequential_supervision_val_scores.append(val_scores)\n",
    "    \n",
    "    return sequential_supervision_val_scores, sequential_supervision_test_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d62e8cb5-d767-4856-b8d9-17b7240641bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 1:20:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.253873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.159801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.102350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.068579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.054615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-2\n",
      "Configuration saved in data/models_2023080710/checkpoint-2/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-2/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-2/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-2/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-4\n",
      "Configuration saved in data/models_2023080710/checkpoint-4/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-4/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-4/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-4/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-6\n",
      "Configuration saved in data/models_2023080710/checkpoint-6/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-6/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-6/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-6/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710/checkpoint-2] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-8\n",
      "Configuration saved in data/models_2023080710/checkpoint-8/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-8/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-8/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-8/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710/checkpoint-4] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-10\n",
      "Configuration saved in data/models_2023080710/checkpoint-10/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-10/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-10/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-10/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_2023080710/checkpoint-10 (score: 4.054614543914795).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 1:22:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.527111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.394960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.332160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.308984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.302174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-13\n",
      "Configuration saved in data/models_20230807100/checkpoint-13/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-13/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-13/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-13/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-26\n",
      "Configuration saved in data/models_20230807100/checkpoint-26/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-26/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-26/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-26/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-39\n",
      "Configuration saved in data/models_20230807100/checkpoint-39/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-39/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-39/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-39/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100/checkpoint-13] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-52\n",
      "Configuration saved in data/models_20230807100/checkpoint-52/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-52/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-52/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-52/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100/checkpoint-26] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-65\n",
      "Configuration saved in data/models_20230807100/checkpoint-65/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-65/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-65/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-65/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100/checkpoint-39] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_20230807100/checkpoint-65 (score: 3.3021740913391113).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 625\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 1:37:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.018964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.971426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.962867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.962022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.961788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-125\n",
      "Configuration saved in data/models_202308071000/checkpoint-125/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-125/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-125/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-125/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-250\n",
      "Configuration saved in data/models_202308071000/checkpoint-250/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-250/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-250/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-375\n",
      "Configuration saved in data/models_202308071000/checkpoint-375/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-375/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-375/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-375/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_202308071000/checkpoint-125] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-500\n",
      "Configuration saved in data/models_202308071000/checkpoint-500/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_202308071000/checkpoint-250] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-625\n",
      "Configuration saved in data/models_202308071000/checkpoint-625/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-625/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-625/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-625/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_202308071000/checkpoint-375] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_202308071000/checkpoint-625 (score: 2.9617884159088135).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6250\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 4:10:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.771644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.884500</td>\n",
       "      <td>2.733512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.884500</td>\n",
       "      <td>2.721585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.649800</td>\n",
       "      <td>2.717716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.543100</td>\n",
       "      <td>2.719046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-1250\n",
      "Configuration saved in data/models_2023080710000/checkpoint-1250/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-1250/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-1250/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-1250/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-2500\n",
      "Configuration saved in data/models_2023080710000/checkpoint-2500/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-3750\n",
      "Configuration saved in data/models_2023080710000/checkpoint-3750/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-3750/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-3750/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-3750/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710000/checkpoint-1250] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-5000\n",
      "Configuration saved in data/models_2023080710000/checkpoint-5000/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710000/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-6250\n",
      "Configuration saved in data/models_2023080710000/checkpoint-6250/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-6250/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-6250/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-6250/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710000/checkpoint-3750] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_2023080710000/checkpoint-5000 (score: 2.7177157402038574).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62500/62500 29:24:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.616300</td>\n",
       "      <td>2.512237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.488800</td>\n",
       "      <td>2.451821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.392700</td>\n",
       "      <td>2.422847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.352500</td>\n",
       "      <td>2.407537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.315900</td>\n",
       "      <td>2.402459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-12500\n",
      "Configuration saved in data/models_20230807100000/checkpoint-12500/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-12500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-25000\n",
      "Configuration saved in data/models_20230807100000/checkpoint-25000/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-25000/special_tokens_map.json\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-37500\n",
      "Configuration saved in data/models_20230807100000/checkpoint-37500/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100000/checkpoint-12500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-62500\n",
      "Configuration saved in data/models_20230807100000/checkpoint-62500/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-62500/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100000/checkpoint-37500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_20230807100000/checkpoint-62500 (score: 2.402458906173706).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 108000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 108000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='867' max='67500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  867/67500 23:08 < 29:42:35, 0.62 it/s, Epoch 0.06/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 37\u001b[0m\n\u001b[1;32m     12\u001b[0m args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     13\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(MODEL_DIR)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(idx_batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m save_total_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     30\u001b[0m             model,\n\u001b[1;32m     31\u001b[0m             args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m             data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m     36\u001b[0m         )\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluating on validation set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m trainer\u001b[38;5;241m.\u001b[39meval_dataset\u001b[38;5;241m=\u001b[39mencoded_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/trainer.py:1317\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1314\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1316\u001b[0m )\n\u001b[0;32m-> 1317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/trainer.py:1556\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m-> 1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1557\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1560\u001b[0m ):\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequential_supervision_val_scores, sequential_supervision_test_scores = train_model_series_with_sequential_sampler(compute_metrics=compute_metrics)\n",
    "print([score['eval_accuracy'] for score in sequential_supervision_val_scores])\n",
    "print([score['eval_accuracy'] for score in sequential_supervision_test_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db053518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('sequential_trainerer_val_agnews_generative.json', 'w+') as f:\n",
    "    json.dump(sequential_supervision_val_scores, f)\n",
    "with open(MODEL_DIR_NEW.joinpath(\"sequential_trainerer_test_agnews_generative.json\"), \"w+\") as f:\n",
    "    json.dump(sequential_supervision_test_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1334817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22a321b3-e67f-4d35-b746-170df21e9bd5",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5939d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/models_2023080710/checkpoint-10\n",
      "data/models_20230807100/checkpoint-65\n",
      "data/models_202308071000/checkpoint-625\n",
      "data/models_2023080710000/checkpoint-6250\n",
      "data/models_20230807100000/checkpoint-62500\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "MODEL_DIR_STUB = Path(f\"data/models_20230807\")\n",
    "def compose_model_dir_path(model_dir_stub=None, num_data_points=None, checkpoint_num=None):\n",
    "    dir_path = f\"{str(model_dir_stub)}{num_data_points}/checkpoint-{checkpoint_num}\"\n",
    "    print(dir_path)\n",
    "    return dir_path\n",
    "\n",
    "model_dir_paths = {10: compose_model_dir_path(MODEL_DIR_STUB, 10, 10),\n",
    "                   100: compose_model_dir_path(MODEL_DIR_STUB, 100, 65),\n",
    "                   1000: compose_model_dir_path(MODEL_DIR_STUB, 1000, 625),\n",
    "                   10000: compose_model_dir_path(MODEL_DIR_STUB, 10000, 6250),\n",
    "                   100000: compose_model_dir_path(MODEL_DIR_STUB, 100000, 62500)\n",
    "                  } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751677f4-aa76-4893-901b-f082b061cecc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "num_data_pts = 1000\n",
    "model_dir = model_dir_paths[num_data_pts]\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "problem_type=\"multi_label_classification\")\n",
    "\n",
    "#config = AutoConfig.from_pretrained(model_dir)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ef41fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Given news article: Afghan Army Dispatched to Calm Violence KABUL, Afghanistan - Government troops intervened in Afghanistan's latest outbreak of deadly fighting between warlords, flying from the capital to the far west on U.S. and NATO airplanes to retake an air base contested in the violence, officials said Sunday...The news article topic is: \",\n",
       " 'World')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler_idx = 39\n",
    "sample = encoded_dataset['test'][sampler_idx]\n",
    "sample_input = tokenizer.decode(sample['input_ids'])\n",
    "sample_input, sample['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b1fa2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "max_new_tokens = 10\n",
    "\n",
    "prefix3 = f\"Classify the following news article as one amongst the following topics 'World', 'Sports', 'Business' or 'Sci/Tech'.\"\n",
    "prompt = prefix3 + sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04d04369",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m sample_gen_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(inputs\u001b[38;5;241m=\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39mmax_new_tokens)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample_gen_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m gen_label_start_index \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors='pt')['input_ids']\n",
    "sample_gen_output = model.generate(inputs=inputs, max_new_tokens=max_new_tokens)\n",
    "print(sample_gen_output.shape)\n",
    "\n",
    "gen_label_start_index = inputs.shape[1]\n",
    "gen_label_end_index = gen_label_start_index+max_new_tokens\n",
    "gen_label_indices = torch.tensor(list(range(gen_label_start_index, gen_label_end_index)))\n",
    "gen_label = torch.index_select(sample_gen_output, 1, gen_label_indices)\n",
    "gen_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.batch_decode(gen_label))\n",
    "tokenizer.batch_decode(sample_gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f8b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "585976b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 10\n",
    "prefix_test = f\"Classify the following news article as one amongst the following topics 'World', 'Sports', 'Business' or 'Sci/Tech'.\"\n",
    "preds = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c677de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_preds_for_model_trained_on_n_data_points(num_data_pts):\n",
    "    model_dir = model_dir_paths[num_data_pts]\n",
    "    print(model_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "    problem_type=\"multi_label_classification\")\n",
    "    model.config.pad_token_id = model.config.eos_token_id    \n",
    "    \n",
    "    preds = []\n",
    "    for i, sample in enumerate(tqdm(encoded_dataset['test'])):\n",
    "        sample = encoded_dataset['test'][i]\n",
    "        sample_input = tokenizer.decode(sample['input_ids'])\n",
    "        prompt = prefix_test + sample_input\n",
    "        inputs = tokenizer(prompt, return_tensors='pt')['input_ids']\n",
    "        sample_gen_output = model.generate(inputs=inputs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "        gen_label_start_index = inputs.shape[1]\n",
    "        gen_label_end_index = gen_label_start_index+max_new_tokens\n",
    "        gen_label_indices = torch.tensor(list(range(gen_label_start_index, gen_label_end_index)))\n",
    "        try: \n",
    "            gen_label = torch.index_select(sample_gen_output, 1, gen_label_indices)\n",
    "        except:\n",
    "            print(i, gen_label_indices) \n",
    "\n",
    "        gen_label_text = tokenizer.batch_decode(gen_label)\n",
    "        preds.append((i, gen_label_text, sample['answer']))\n",
    "        \n",
    "    with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'w+') as f:\n",
    "        json.dump(preds, f)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "426704be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/models_20230807100/checkpoint-65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 94/7600 [00:44<56:20,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 215/7600 [01:41<55:09,  2.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 tensor([104, 105, 106, 107, 108, 109, 110, 111, 112, 113])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 539/7600 [04:12<57:57,  2.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538 tensor([88, 89, 90, 91, 92, 93, 94, 95, 96, 97])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 639/7600 [05:00<53:50,  2.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638 tensor([78, 79, 80, 81, 82, 83, 84, 85, 86, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 944/7600 [07:23<47:07,  2.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 tensor([78, 79, 80, 81, 82, 83, 84, 85, 86, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 1020/7600 [07:58<45:48,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019 tensor([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 1172/7600 [09:09<54:45,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171 tensor([79, 80, 81, 82, 83, 84, 85, 86, 87, 88])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 1193/7600 [09:19<51:52,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192 tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 1277/7600 [09:58<48:03,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1276 tensor([85, 86, 87, 88, 89, 90, 91, 92, 93, 94])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 1541/7600 [12:02<52:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540 tensor([81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 1593/7600 [12:27<44:02,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592 tensor([78, 79, 80, 81, 82, 83, 84, 85, 86, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 1597/7600 [12:28<44:56,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1596 tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 1993/7600 [15:32<40:54,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992 tensor([ 92,  93,  94,  95,  96,  97,  98,  99, 100, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 2109/7600 [16:27<45:13,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108 tensor([72, 73, 74, 75, 76, 77, 78, 79, 80, 81])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 2298/7600 [17:55<38:38,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2297 tensor([79, 80, 81, 82, 83, 84, 85, 86, 87, 88])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 2412/7600 [18:49<37:02,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2411 tensor([81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 2511/7600 [19:36<36:04,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510 tensor([69, 70, 71, 72, 73, 74, 75, 76, 77, 78])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 2541/7600 [19:49<31:57,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540 tensor([82, 83, 84, 85, 86, 87, 88, 89, 90, 91])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 2576/7600 [20:06<36:48,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575 tensor([85, 86, 87, 88, 89, 90, 91, 92, 93, 94])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 2642/7600 [20:36<37:04,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2641 tensor([72, 73, 74, 75, 76, 77, 78, 79, 80, 81])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 3007/7600 [23:26<33:55,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3006 tensor([87, 88, 89, 90, 91, 92, 93, 94, 95, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 3182/7600 [24:48<31:22,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3181 tensor([ 93,  94,  95,  96,  97,  98,  99, 100, 101, 102])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 3678/7600 [28:40<32:06,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3677 tensor([84, 85, 86, 87, 88, 89, 90, 91, 92, 93])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 3734/7600 [29:06<28:11,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733 tensor([83, 84, 85, 86, 87, 88, 89, 90, 91, 92])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 3831/7600 [29:52<26:39,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3830 tensor([86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 3849/7600 [30:00<27:36,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3848 tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 3897/7600 [30:22<26:58,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3896 tensor([89, 90, 91, 92, 93, 94, 95, 96, 97, 98])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 4038/7600 [31:29<25:12,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4037 tensor([86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 4093/7600 [31:54<24:35,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4092 tensor([82, 83, 84, 85, 86, 87, 88, 89, 90, 91])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 4191/7600 [32:41<25:14,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4190 tensor([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 4208/7600 [32:49<24:39,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4207 tensor([101, 102, 103, 104, 105, 106, 107, 108, 109, 110])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 4221/7600 [32:54<25:23,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4220 tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 4247/7600 [33:06<23:25,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4246 tensor([ 92,  93,  94,  95,  96,  97,  98,  99, 100, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 4299/7600 [33:31<24:11,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4298 tensor([87, 88, 89, 90, 91, 92, 93, 94, 95, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 4447/7600 [34:41<22:56,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4446 tensor([ 95,  96,  97,  98,  99, 100, 101, 102, 103, 104])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 4650/7600 [36:16<21:26,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4649 tensor([85, 86, 87, 88, 89, 90, 91, 92, 93, 94])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 4724/7600 [36:50<22:23,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4723 tensor([ 93,  94,  95,  96,  97,  98,  99, 100, 101, 102])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 4778/7600 [37:16<25:04,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4777 tensor([ 95,  96,  97,  98,  99, 100, 101, 102, 103, 104])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 4831/7600 [37:41<20:43,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830 tensor([81, 82, 83, 84, 85, 86, 87, 88, 89, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 4947/7600 [38:34<19:15,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4946 tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 5062/7600 [39:27<18:21,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5061 tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 5528/7600 [43:07<15:35,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5527 tensor([84, 85, 86, 87, 88, 89, 90, 91, 92, 93])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 5553/7600 [43:18<14:52,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5552 tensor([88, 89, 90, 91, 92, 93, 94, 95, 96, 97])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 5732/7600 [44:42<13:54,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5731 tensor([83, 84, 85, 86, 87, 88, 89, 90, 91, 92])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 5791/7600 [45:09<12:57,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5790 tensor([86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 6043/7600 [47:08<10:05,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6042 tensor([79, 80, 81, 82, 83, 84, 85, 86, 87, 88])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 6090/7600 [47:30<10:28,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6089 tensor([66, 67, 68, 69, 70, 71, 72, 73, 74, 75])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 6207/7600 [48:24<09:34,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6206 tensor([83, 84, 85, 86, 87, 88, 89, 90, 91, 92])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 6377/7600 [49:44<09:14,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376 tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 6387/7600 [49:49<09:08,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6386 tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 6388/7600 [49:49<08:43,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6387 tensor([73, 74, 75, 76, 77, 78, 79, 80, 81, 82])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 6934/7600 [54:04<04:51,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6933 tensor([72, 73, 74, 75, 76, 77, 78, 79, 80, 81])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 6964/7600 [54:18<05:15,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6963 tensor([82, 83, 84, 85, 86, 87, 88, 89, 90, 91])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 6989/7600 [54:31<04:49,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6988 tensor([78, 79, 80, 81, 82, 83, 84, 85, 86, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 6996/7600 [54:34<04:45,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6995 tensor([75, 76, 77, 78, 79, 80, 81, 82, 83, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 7202/7600 [56:11<02:46,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7201 tensor([73, 74, 75, 76, 77, 78, 79, 80, 81, 82])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 7229/7600 [56:23<02:25,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7228 tensor([86, 87, 88, 89, 90, 91, 92, 93, 94, 95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 7403/7600 [57:44<01:30,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7402 tensor([87, 88, 89, 90, 91, 92, 93, 94, 95, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7600/7600 [59:16<00:00,  2.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data_pts = 100\n",
    "preds2 = generate_preds_for_model_trained_on_n_data_points(num_data_pts)\n",
    "len(encoded_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "177fd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load, EvaluationModule\n",
    "bertscore = load(\"bertscore\")\n",
    "rouge = load(\"rouge\")\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "def score_and_pred_label(gen_text, true_label, scorer:EvaluationModule=rouge, reference_classes=classes):\n",
    "    #print(f'Using metric: {scorer.name}')\n",
    "    #scorer = load(metric)\n",
    "    scores_across_classes = []\n",
    "    for ref in reference_classes:\n",
    "        assert isinstance(gen_text, list)\n",
    "        if scorer.name==\"bert_score\":\n",
    "            scores_across_classes.append(scorer.compute(predictions=gen_text, references=[ref], lang=\"en\"))\n",
    "            precision_scores = [score['precision'] for score in scores_across_classes]\n",
    "\n",
    "        else:\n",
    "            scores_across_classes.append(scorer.compute(predictions=gen_text, references=[ref]))\n",
    "            precision_scores = [score['rougeL'] for score in scores_across_classes]\n",
    "    pred_label = np.array(precision_scores).argmax()\n",
    "    #print(f\"for generated label {gen_text}, highest scoring label is {reference_classes[pred_label]}, true label: {true_label} \\n\")\n",
    "    return pred_label, label2id.get(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d5778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_preds(num_data_pts, scorer=bertscore):\n",
    "    with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'r') as f:\n",
    "        preds = json.load(f)\n",
    "    pred_labels_by_scorer = []\n",
    "    true_labels = []\n",
    "    tp = 0\n",
    "    for idx, item in tqdm(enumerate(preds)):\n",
    "        _, gen_text, true_label = item\n",
    "        pred_label, true_label = score_and_pred_label(gen_text=gen_text, true_label=true_label, scorer=scorer)\n",
    "        if pred_label==true_label:\n",
    "            tp+=1\n",
    "        pred_labels_by_scorer.append(pred_label)\n",
    "        true_labels.append(true_label)\n",
    "        \n",
    "    acc = tp/len(preds)\n",
    "    print(scorer.name, num_data_pts, acc)\n",
    "    return acc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d5999a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_data_pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/predictions/genai_agnews_clf_pred_labels_numdatapts_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_data_pts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m preds[:\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "num_data_pts = 100\n",
    "with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'r') as f:\n",
    "    preds = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41c3fc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [1:34:49,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge 100 0.3325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3325"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "num_data_pts = 100\n",
    "acc = score_preds(num_data_pts, scorer=rouge)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415af40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0491a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [1:33:57,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge 1000 0.4955263157894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4955263157894737"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_data_pts = 1000\n",
    "acc = score_preds(num_data_pts, scorer=rouge)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9f6c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3365it [57:22,  1.02s/it]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "4337it [1:13:55,  1.04s/it]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_scores = []\n",
    "for num_data_pts in [10000, 100000]:\n",
    "    for scorer in [rouge]:\n",
    "        acc = score_preds(num_data_pts, scorer=scorer)\n",
    "        acc_scores.append((num_data_pts, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bba2a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10000, 0.6228947368421053), (100000, 0.7094736842105264)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbefd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbf205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1def6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'w+') as f:\n",
    "    json.dump(preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "064a5338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6228947368421053"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels_bertscore = []\n",
    "true_labels = []\n",
    "tp = 0\n",
    "for idx, item in enumerate(preds):\n",
    "    _, gen_text, true_label = item\n",
    "    pred_label, true_label = score_and_pred_label(gen_text=gen_text, true_label=true_label, scorer=rouge)\n",
    "    if pred_label==true_label:\n",
    "        tp+=1\n",
    "    pred_labels_bertscore.append(pred_label)\n",
    "    true_labels.append(true_label)\n",
    "\n",
    "print(num_data_pts)\n",
    "acc = tp/len(preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1e1b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c15d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "num_data_pts\n",
    "with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'r') as f:\n",
    "    preds = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23defa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, [' World, Business, Sci/Tech.The news'], 'World']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7caa34fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17ea9f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'World': 0, 'Sports': 1, 'Business': 2, 'Sci/Tech': 3}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "rouge = load(\"rouge\")\n",
    "# results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6571947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, predictions, true_labels = zip(*preds)\n",
    "#bertscore.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "981bce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load, EvaluationModule\n",
    "bertscore = load(\"bertscore\")\n",
    "rouge = load(\"rouge\")\n",
    "def score_and_pred_label(gen_text, true_label, scorer:EvaluationModule=rouge, reference_classes=references):\n",
    "    #print(f'Using metric: {scorer.name}')\n",
    "    #scorer = load(metric)\n",
    "    scores_across_classes = []\n",
    "    for ref in reference_classes:\n",
    "        assert isinstance(gen_text, list)\n",
    "        if scorer.name==\"bert_score\":\n",
    "            scores_across_classes.append(scorer.compute(predictions=gen_text, references=[ref], lang=\"en\"))\n",
    "            precision_scores = [score['precision'] for score in scores_across_classes]\n",
    "\n",
    "        else:\n",
    "            scores_across_classes.append(scorer.compute(predictions=gen_text, references=[ref]))\n",
    "            precision_scores = [score['rougeL'] for score in scores_across_classes]\n",
    "    pred_label = np.array(precision_scores).argmax()\n",
    "    #print(f\"for generated label {gen_text}, highest scoring label is {reference_classes[pred_label]}, true label: {true_label} \\n\")\n",
    "    return pred_label, label2id.get(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7549de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'r') as f:\n",
    "    preds = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31d3d1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 21\n",
    "_, gen_text, true_label = preds[idx]\n",
    "score_and_pred_label(gen_text=gen_text, true_label=true_label,  scorer=bertscore)\n",
    "score_and_pred_label(gen_text=gen_text, true_label=true_label, scorer=rouge)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8296f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_bertscore = []\n",
    "true_labels = []\n",
    "tp = 0\n",
    "for idx, item in enumerate(preds):\n",
    "    _, gen_text, true_label = item\n",
    "    pred_label, true_label = score_and_pred_label(gen_text=gen_text, true_label=true_label, scorer=rouge)\n",
    "    if pred_label==true_label:\n",
    "        tp+=1\n",
    "    pred_labels_bertscore.append(pred_label)\n",
    "    true_labels.append(true_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b38d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12c018aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data_pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5626c9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6228947368421053"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acc = tp/len(preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fc4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e860ede5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6c07717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094736842105264"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = tp/len(preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52f849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-bioblp-env [Python]",
   "language": "python",
   "name": "conda-env-.conda-bioblp-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
