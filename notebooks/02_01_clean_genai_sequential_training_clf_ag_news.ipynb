{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde91e79",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec32a6",
   "metadata": {},
   "source": [
    "### imports and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09253d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_SMALL = \"t5-small\"\n",
    "GPT = \"gpt2\"  # 117M parameters as per https://huggingface.co/transformers/v3.3.1/pretrained_models.html # \"openai-gpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac0c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "from collections import defaultdict\n",
    "\n",
    "# mandatory imports\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data import random_split\n",
    "import collections\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from typing import Callable\n",
    "from transformers import EarlyStoppingCallback\n",
    "from training_utils import SequentialTrainingBatchSampler\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "#from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5e2c8",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d0b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset\n",
    "DATASET_AGNEWS = 'ag_news'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838b0c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615d45ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/jovyan/llm_peft_exploration/notebooks/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8bf46ac4c54994bdf2e05340fc154d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dataset = load_dataset(DATASET_AGNEWS, cache_dir=\"./datasets/.cache/huggingface_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dc9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "id2label = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "\n",
    "label2id = {v:k for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb798a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f2abf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 120000, 'test': 7600}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(raw_dataset[k]) for k in raw_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c046722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test'][0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8541c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb537953",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preprocessing params\n",
    "MAX_INPUT_LENGTH = 364\n",
    "stride = 128\n",
    "\n",
    "### Tokenizer config\n",
    "tokenizer = AutoTokenizer.from_pretrained(GPT)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'  # 'left'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a6ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix1 = \"Given news article: \"\n",
    "prefix2 = \"The news article topic is: \"\n",
    "\n",
    "\n",
    "def prepare_dataset(ds, tokenizer, create_validation_split=False, validation_prop=0.1, remove_columns=[]):\n",
    "    train_dataset = ds['train'].map(preprocess_data, batched=True, remove_columns=remove_columns)\n",
    "    test_dataset = ds['test'].map(preprocess_test_data, batched=True, remove_columns=remove_columns)\n",
    "\n",
    "    train_dataset.set_format(\"torch\")\n",
    "    validation_dataset = None\n",
    "    # carve out validation set from train\n",
    "    print(f\"creating validation split: {str(create_validation_split)}\")\n",
    "    if create_validation_split:\n",
    "        # had forgotten to add random split earlier during the seq training exercise\n",
    "        train_dataset, validation_dataset= train_dataset.train_test_split(test_size=validation_prop).values()\n",
    "    return {'train': train_dataset, 'valid': validation_dataset, 'test': test_dataset}\n",
    "\n",
    "\n",
    "def preprocess_data(examples, max_input_length = MAX_INPUT_LENGTH):\n",
    "    # https://huggingface.co/learn/nlp-course/chapter7/6?fw=tf#preparing-the-dataset\n",
    "    context = [prefix1 + doc for doc in examples[\"text\"] ]\n",
    "    topic_labels = [id2label[q] for q in examples[\"label\"]]\n",
    "    prepped_topics = [prefix2+ topic for topic in topic_labels]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        context,\n",
    "        prepped_topics,\n",
    "        max_length=max_input_length,\n",
    "        truncation=\"only_first\",\n",
    "        #stride=stride,\n",
    "        #return_overflowing_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # labels shift input_ids \n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def preprocess_test_data(examples):\n",
    "    context = [prefix1 + doc + prefix2 for doc in examples[\"text\"] ]\n",
    "    topic_labels = [id2label[q] for q in examples[\"label\"]]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        context,\n",
    "    )\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
    "    inputs[\"answer\"] = topic_labels\n",
    "\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072aed0",
   "metadata": {},
   "source": [
    "#### encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d597160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/llm_peft_exploration/notebooks/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-916a9b28d4526ffb.arrow\n",
      "Loading cached processed dataset at /home/jovyan/llm_peft_exploration/notebooks/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-b2b255dbd88aa3a1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating validation split: True\n"
     ]
    }
   ],
   "source": [
    "# tokenize \n",
    "encoded_dataset = prepare_dataset(raw_dataset, tokenizer, create_validation_split=True,  remove_columns=[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3713757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data sample:  Given news article: Israel Kills 5 in Attempt to Assassinate Hamas Man  GAZA (Reuters) - A senior Hamas leader survived an Israeli  assassination attempt on Wednesday but at least five other  Palestinians were killed in the night-time explosion that tore  through his Gaza home.The news article topic is: World \n",
      " Given news article: Israel Kills 5 in Attempt to Assassinate Hamas Man  GAZA (Reuters) - A senior Hamas leader survived an Israeli  assassination attempt on Wednesday but at least five other  Palestinians were killed in the night-time explosion that tore  through his Gaza home.The news article topic is: World\n",
      "test data sample:  Given news article: Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.The news article topic is:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('training data sample: ', tokenizer.decode(encoded_dataset['train'][2]['input_ids'], skip_special_tokens=True), '\\n', tokenizer.decode(encoded_dataset['train'][2]['labels'], skip_special_tokens=True))\n",
    "# we have intentionally not padded test sentences\n",
    "print('test data sample: ', tokenizer.decode(encoded_dataset['test'][2]['input_ids'], skip_special_tokens=True), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312022d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ae151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SIZE = 0.1\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "METRIC_NAME = \"f1\"\n",
    "N_EPOCHS = 100\n",
    "BASE = 10\n",
    "MODEL_DIR = Path(f\"data/models_20230807\")\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca1d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "#model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1cd53b",
   "metadata": {},
   "source": [
    "### Experiment: Sequential training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f5671",
   "metadata": {},
   "source": [
    "test how the accuracy improves with batches of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "838914e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sequential_sampler = SequentialTrainingBatchSampler(encoded_dataset['train'], batch_size=-1, base=BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bc520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_series_with_sequential_sampler(batch_size=BATCH_SIZE, n_epochs=5,\n",
    "                                              compute_metrics: Callable = None, output_model_dir=MODEL_DIR, \n",
    "                                               learning_rate=LEARNING_RATE, metric_name=METRIC_NAME,\n",
    "                                              custom_sequential_sampler=custom_sequential_sampler):\n",
    "    total_subset_idx = []\n",
    "    sequential_supervision_val_scores = []\n",
    "    sequential_supervision_test_scores = []\n",
    "    for idx, idx_batch in enumerate(custom_sequential_sampler):\n",
    "        print(idx)\n",
    "        if idx>4:\n",
    "            break\n",
    "        sequence_n_output_dir = output_model_dir.joinpath(f\"_{idx}\")\n",
    "        batch_dataset = Subset(encoded_dataset['train'], idx_batch)\n",
    "        print(f\"Number of training data points: {len(idx_batch)}\")\n",
    "        args = TrainingArguments(\n",
    "            output_dir=sequence_n_output_dir,\n",
    "            evaluation_strategy=\"steps\", #epoch\",\n",
    "            eval_steps = 500,\n",
    "            save_strategy=\"steps\", #epoch\",\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=n_epochs,\n",
    "            weight_decay=0.01,\n",
    "            metric_for_best_model=metric_name,\n",
    "            logging_dir='./logs',            # directory for storing logs*\n",
    "            logging_steps=2000,\n",
    "            # report_to='wandb',\n",
    "            load_best_model_at_end = True,\n",
    "            save_total_limit = 2,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "                    model,\n",
    "                    args,\n",
    "                    train_dataset=batch_dataset,\n",
    "                    eval_dataset=encoded_dataset['valid'],\n",
    "                    tokenizer=tokenizer,\n",
    "                    compute_metrics=compute_metrics,\n",
    "            #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "                    #data_collator=data_collator\n",
    "                )\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "        print(f\"evaluating on test set\")\n",
    "        trainer.eval_dataset=encoded_dataset['test']\n",
    "        test_scores = trainer.evaluate()\n",
    "        sequential_supervision_test_scores.append(test_scores)\n",
    "        #trainer.save()\n",
    "\n",
    "\n",
    "        print(f\"evaluating on validation set\")\n",
    "        trainer.eval_dataset=encoded_dataset['valid']\n",
    "        val_scores = trainer.evaluate()        \n",
    "        sequential_supervision_val_scores.append(val_scores)\n",
    "    \n",
    "    return sequential_supervision_val_scores, sequential_supervision_test_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2f59e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 1:20:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.253873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.159801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.102350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.068579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.054615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-2\n",
      "Configuration saved in data/models_2023080710/checkpoint-2/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-2/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-2/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-2/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-4\n",
      "Configuration saved in data/models_2023080710/checkpoint-4/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-4/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-4/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-4/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-6\n",
      "Configuration saved in data/models_2023080710/checkpoint-6/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-6/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-6/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-6/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710/checkpoint-2] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-8\n",
      "Configuration saved in data/models_2023080710/checkpoint-8/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-8/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-8/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-8/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710/checkpoint-4] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710/checkpoint-10\n",
      "Configuration saved in data/models_2023080710/checkpoint-10/config.json\n",
      "Model weights saved in data/models_2023080710/checkpoint-10/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710/checkpoint-10/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710/checkpoint-10/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_2023080710/checkpoint-10 (score: 4.054614543914795).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 1:22:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.527111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.394960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.332160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.308984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.302174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-13\n",
      "Configuration saved in data/models_20230807100/checkpoint-13/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-13/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-13/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-13/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-26\n",
      "Configuration saved in data/models_20230807100/checkpoint-26/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-26/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-26/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-26/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-39\n",
      "Configuration saved in data/models_20230807100/checkpoint-39/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-39/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-39/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-39/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100/checkpoint-13] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-52\n",
      "Configuration saved in data/models_20230807100/checkpoint-52/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-52/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-52/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-52/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100/checkpoint-26] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100/checkpoint-65\n",
      "Configuration saved in data/models_20230807100/checkpoint-65/config.json\n",
      "Model weights saved in data/models_20230807100/checkpoint-65/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100/checkpoint-65/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100/checkpoint-65/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100/checkpoint-39] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_20230807100/checkpoint-65 (score: 3.3021740913391113).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 625\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 1:37:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.018964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.971426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.962867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.962022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.961788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-125\n",
      "Configuration saved in data/models_202308071000/checkpoint-125/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-125/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-125/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-125/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-250\n",
      "Configuration saved in data/models_202308071000/checkpoint-250/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-250/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-250/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-375\n",
      "Configuration saved in data/models_202308071000/checkpoint-375/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-375/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-375/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-375/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_202308071000/checkpoint-125] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-500\n",
      "Configuration saved in data/models_202308071000/checkpoint-500/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_202308071000/checkpoint-250] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_202308071000/checkpoint-625\n",
      "Configuration saved in data/models_202308071000/checkpoint-625/config.json\n",
      "Model weights saved in data/models_202308071000/checkpoint-625/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_202308071000/checkpoint-625/tokenizer_config.json\n",
      "Special tokens file saved in data/models_202308071000/checkpoint-625/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_202308071000/checkpoint-375] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_202308071000/checkpoint-625 (score: 2.9617884159088135).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6250\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 4:10:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.771644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.884500</td>\n",
       "      <td>2.733512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.884500</td>\n",
       "      <td>2.721585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.649800</td>\n",
       "      <td>2.717716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.543100</td>\n",
       "      <td>2.719046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-1250\n",
      "Configuration saved in data/models_2023080710000/checkpoint-1250/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-1250/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-1250/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-1250/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-2500\n",
      "Configuration saved in data/models_2023080710000/checkpoint-2500/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-3750\n",
      "Configuration saved in data/models_2023080710000/checkpoint-3750/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-3750/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-3750/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-3750/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710000/checkpoint-1250] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-5000\n",
      "Configuration saved in data/models_2023080710000/checkpoint-5000/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710000/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_2023080710000/checkpoint-6250\n",
      "Configuration saved in data/models_2023080710000/checkpoint-6250/config.json\n",
      "Model weights saved in data/models_2023080710000/checkpoint-6250/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_2023080710000/checkpoint-6250/tokenizer_config.json\n",
      "Special tokens file saved in data/models_2023080710000/checkpoint-6250/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_2023080710000/checkpoint-3750] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_2023080710000/checkpoint-5000 (score: 2.7177157402038574).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62500/62500 29:24:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.616300</td>\n",
       "      <td>2.512237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.488800</td>\n",
       "      <td>2.451821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.392700</td>\n",
       "      <td>2.422847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.352500</td>\n",
       "      <td>2.407537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.315900</td>\n",
       "      <td>2.402459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-12500\n",
      "Configuration saved in data/models_20230807100000/checkpoint-12500/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-12500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-25000\n",
      "Configuration saved in data/models_20230807100000/checkpoint-25000/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-25000/special_tokens_map.json\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-37500\n",
      "Configuration saved in data/models_20230807100000/checkpoint-37500/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100000/checkpoint-12500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to data/models_20230807100000/checkpoint-62500\n",
      "Configuration saved in data/models_20230807100000/checkpoint-62500/config.json\n",
      "Model weights saved in data/models_20230807100000/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in data/models_20230807100000/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in data/models_20230807100000/checkpoint-62500/special_tokens_map.json\n",
      "Deleting older checkpoint [data/models_20230807100000/checkpoint-37500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/models_20230807100000/checkpoint-62500 (score: 2.402458906173706).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 15:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 108000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set\n",
      "Number of training data points: 108000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='867' max='67500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  867/67500 23:08 < 29:42:35, 0.62 it/s, Epoch 0.06/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 37\u001b[0m\n\u001b[1;32m     12\u001b[0m args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     13\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(MODEL_DIR)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(idx_batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m save_total_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     30\u001b[0m             model,\n\u001b[1;32m     31\u001b[0m             args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m             data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m     36\u001b[0m         )\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluating on validation set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m trainer\u001b[38;5;241m.\u001b[39meval_dataset\u001b[38;5;241m=\u001b[39mencoded_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/trainer.py:1317\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1314\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1316\u001b[0m )\n\u001b[0;32m-> 1317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/trainer.py:1556\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m-> 1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1557\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1560\u001b[0m ):\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequential_supervision_val_scores, sequential_supervision_test_scores = train_model_series_with_sequential_sampler(compute_metrics=compute_metrics)\n",
    "print([score['eval_accuracy'] for score in sequential_supervision_val_scores])\n",
    "print([score['eval_accuracy'] for score in sequential_supervision_test_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cb9a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('sequential_trainerer_val_agnews_generative.json', 'w+') as f:\n",
    "    json.dump(sequential_supervision_val_scores, f)\n",
    "with open(MODEL_DIR_NEW.joinpath(\"sequential_trainerer_test_agnews_generative.json\"), \"w+\") as f:\n",
    "    json.dump(sequential_supervision_test_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf196a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bbf9e2d",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75a0dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/models_2023080710/checkpoint-10\n",
      "data/models_20230807100/checkpoint-65\n",
      "data/models_202308071000/checkpoint-625\n",
      "data/models_2023080710000/checkpoint-6250\n",
      "data/models_20230807100000/checkpoint-62500\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR_STUB = Path(f\"data/models_20230807\")\n",
    "\n",
    "def compose_model_dir_path(model_dir_stub=None, num_data_points=None, checkpoint_num=None):\n",
    "    dir_path = f\"{str(model_dir_stub)}{num_data_points}/checkpoint-{checkpoint_num}\"\n",
    "    print(dir_path)\n",
    "    return dir_path\n",
    "\n",
    "model_dir_paths = {10: compose_model_dir_path(MODEL_DIR_STUB, 10, 10),\n",
    "                   100: compose_model_dir_path(MODEL_DIR_STUB, 100, 65),\n",
    "                   1000: compose_model_dir_path(MODEL_DIR_STUB, 1000, 625),\n",
    "                   10000: compose_model_dir_path(MODEL_DIR_STUB, 10000, 6250),\n",
    "                   100000: compose_model_dir_path(MODEL_DIR_STUB, 100000, 62500)\n",
    "                  } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad3a54",
   "metadata": {},
   "source": [
    "define utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d96da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens=3\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token # to avoid an error\n",
    "prefix_test = f\"Classify the following news article as one amongst the following topics 'World', 'Sports', 'Business' or 'Sci/Tech'.\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd3f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inference_data(examples):\n",
    "    context = [prefix_test + prefix1 + doc + prefix2 for doc in examples[\"text\"] ]\n",
    "    topic_labels = [id2label[q] for q in examples[\"label\"]]\n",
    "    inputs = tokenizer(\n",
    "        context,\n",
    "        padding=True, #or =do_not_pad, and set as 'left' padding before preprocessing,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    inputs[\"text\"]=context\n",
    "    inputs[\"answer\"] = topic_labels\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def load_model_trained_on_n_data_points(num_data_pts, device=device):\n",
    "    model_dir = model_dir_paths[num_data_pts]\n",
    "    print(model_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "    problem_type=\"multi_label_classification\").to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_preds_for_model_trained_on_n_data_points(num_data_pts, test_dataset=encoded_dataset['test'], max_new_tokens=max_new_tokens):\n",
    "    model = load_model_trained_on_n_data_points(num_data_pts)\n",
    "    model.config.pad_token_id = model.config.eos_token_id    \n",
    "    preds = [] \n",
    "    preds_batches = []\n",
    "    data_loader = DataLoader(test_dataset, batch_size=8)\n",
    "    for idx, batch in enumerate(tqdm(data_loader)):\n",
    "        texts = batch['text']\n",
    "        encoding = tokenizer(texts, padding=True, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(top_k=5, eos_token_id=model.config.eos_token_id, max_new_tokens=max_new_tokens, **encoding).to(device)\n",
    "        generated_texts = tokenizer.batch_decode(generated_ids[:, -max_new_tokens:], skip_special_tokens=True)\n",
    "        preds_batches.append(list(zip(generated_texts, batch['answer'])))\n",
    "    \n",
    "    preds_flattened = [item for batch in preds_batches for item in batch]    \n",
    "    \n",
    "    with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'w+') as f:\n",
    "        json.dump(preds_flattened, f)\n",
    "    return preds_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d1e7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0c88bdb12143349726c2901e17c76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask', 'answer'],\n",
       "    num_rows: 7600\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = raw_dataset['test'].map(preprocess_inference_data, batched=True, batch_size=BATCH_SIZE, remove_columns=[\"label\"])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872cde0c",
   "metadata": {},
   "source": [
    "#### try it out on a sample data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eda50a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,\n",
       " \"<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Classify the following news article as one amongst the following topics 'World', 'Sports', 'Business' or 'Sci/Tech'.Given news article: Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.The news article topic is: \",\n",
       " 'Sci/Tech',\n",
       " \"Classify the following news article as one amongst the following topics 'World', 'Sports', 'Business' or 'Sci/Tech'.Given news article: Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.The news article topic is: \")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler_idx = 2\n",
    "sample = test_data[sampler_idx]\n",
    "sample_input = tokenizer.decode(sample['input_ids'])\n",
    "len(sample['input_ids']), sample_input, sample['answer'], sample['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2035b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/models_202308071000/checkpoint-625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Classify the following news article as one amongst the following topics 'World', 'Sports', 'Business' or 'Sci/Tech'.Given news article: Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.The news article topic is:  World, Business\",\n",
       " \"Classify the following news article as one amongst the following topics 'World', 'Sports', 'Business' or 'Sci/Tech'.Given news article: The Race is On: Second Private Team Sets Launch Date for Human Spaceflight (SPACE.com) SPACE.com - TORONTO, Canada -- A second\\\\team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for\\\\privately funded suborbital space flight, has officially announced the first\\\\launch date for its manned rocket.The news article topic is:  Sci/Tech\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = test_data['text'][:2]\n",
    "encoding = tokenizer(texts, padding=True, return_tensors='pt').to(device)\n",
    "model = load_model_trained_on_n_data_points(1000).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(**encoding, max_new_tokens=max_new_tokens)\n",
    "generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "generated_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13be64b",
   "metadata": {},
   "source": [
    "#### run on full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4345fc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/models_20230807100/checkpoint-65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_data_pts in [100, 1000, 10000, 100000]:\n",
    "    preds = generate_preds_for_model_trained_on_n_data_points(num_data_pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358d3c3",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39567d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec64f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load, EvaluationModule\n",
    "import numpy\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "bertscore = load(\"bertscore\")\n",
    "rouge = load(\"rouge\")\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "from typing import Tuple\n",
    "def score_gen_text_and_assign_label(gen_text, true_label, scorer:EvaluationModule=rouge, reference_classes=classes, verbose=False):\n",
    "    scores_across_classes = []\n",
    "    for ref in reference_classes:\n",
    "        if scorer.name==\"bert_score\":\n",
    "            scores_across_classes.append(scorer.compute(predictions=[gen_text], references=[ref], lang=\"en\"))\n",
    "            precision_scores = [score['precision'] for score in scores_across_classes]\n",
    "\n",
    "        else:\n",
    "            scores_across_classes.append(scorer.compute(predictions=[gen_text], references=[ref]))\n",
    "            precision_scores = [score['rougeL'] for score in scores_across_classes]\n",
    "    pred_label = numpy.array(precision_scores).argmax()\n",
    "    if verbose:\n",
    "        print(f\"for generated label {gen_text}, highest scoring label is {reference_classes[pred_label]}, true label: {true_label} \\n\")\n",
    "    return pred_label, label2id.get(true_label)\n",
    "\n",
    "def score_preds(num_data_pts, scorer=bertscore):\n",
    "    with open(f'data/predictions/genai_agnews_clf_pred_labels_numdatapts_{num_data_pts}.json', 'r') as f:\n",
    "        preds = json.load(f)\n",
    "    pred_labels_by_scorer = []\n",
    "    true_labels = []\n",
    "    tp = 0\n",
    "    for item in tqdm(preds):\n",
    "        gen_text, true_label = item\n",
    "        pred_label_id, true_label_id = score_gen_text_and_assign_label(gen_text=gen_text, true_label=true_label, scorer=scorer)\n",
    "        if pred_label_id==true_label_id:\n",
    "            tp+=1\n",
    "        pred_labels_by_scorer.append(pred_label_id)\n",
    "        true_labels.append(true_label_id)\n",
    "        \n",
    "    acc = tp/len(preds)\n",
    "    print(scorer.name, num_data_pts, acc)\n",
    "    return acc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_pts = 100000\n",
    "acc = score_preds(num_data_pts, scorer=rouge)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81e26549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7600/7600 [2:08:39<00:00,  1.02s/it]s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge 100 0.3215789473684211\n",
      "Completed in 7719.489288806915 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7600/7600 [2:08:46<00:00,  1.02s/it]t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge 10000 0.6372368421052632\n",
      "Completed in 7726.810903787613 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7600/7600 [2:08:37<00:00,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge 100000 0.5827631578947369\n",
      "Completed in 7717.722070217133 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_scores = []\n",
    "for num_data_pts in [100, 1000, 10000, 100000]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    for scorer in [rouge]:\n",
    "        acc = score_preds(num_data_pts, scorer=scorer)\n",
    "        acc_scores.append((num_data_pts, acc))\n",
    "    print(f\"Completed in {time.time()-start_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "861070cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699139047.2175796\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54fb73ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, 0.3215789473684211),\n",
       " (1000, 0.6001315789473685),\n",
       " (10000, 0.6372368421052632),\n",
       " (100000, 0.5827631578947369)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a54bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dcc80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-bioblp-env [Python]",
   "language": "python",
   "name": "conda-env-.conda-bioblp-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
