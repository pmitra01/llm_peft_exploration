{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce2a79b",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87d886",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "do you want to use collate_fn in data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d4826-da4a-4baa-a01d-11cd6fce8ab1",
   "metadata": {},
   "source": [
    "### imports and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e68c1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_SMALL = \"t5-small\"\n",
    "GPT = \"gpt2\"  # 117M parameters as per https://huggingface.co/transformers/v3.3.1/pretrained_models.html # \"openai-gpt\"\n",
    "DISTILBERT = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5d391-db12-4559-8a75-4fb68d5b144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "from collections import defaultdict\n",
    "\n",
    "# mandatory imports\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data import random_split\n",
    "import collections\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dffa1a-8f35-4ffa-8b88-4b9675cdceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SIZE = 0.1\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "METRIC_NAME = \"f1\"\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192c31b-3784-4d6c-a200-c5f535e60f28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16035507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/jovyan/llm_peft_exploration/datasets/.cache/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb673539a2084f5b8cd6736df6b2bafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#raw_dataset = load_dataset('super_glue', 'cb', cache_dir=\"./datasets/.cache/huggingface_datasets\")\n",
    "raw_dataset = load_dataset('ag_news', cache_dir=\"./datasets/.cache/huggingface_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba172029",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "\n",
    "label2id = {v:k for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6eca9-97ff-45ec-8465-a5b8ee66b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15927ee5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b37d9ca-7147-44fe-a8d3-ae92e0c7d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(GPT)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'  # 'left'\n",
    "\n",
    "# Use `DataCollatorWithPadding` as it is more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding to max length\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3d834-d272-4c5f-b6d6-529ef9b98526",
   "metadata": {},
   "source": [
    "### explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01e1cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 120000, 'test': 7600}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(raw_dataset[k]) for k in raw_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431d804b-af29-4409-bcbc-c84ee122cef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['test'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d2868e-2928-4f0e-a29f-61bae95e65df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randint(0, 10, (8, ))\n",
    "one_hot = torch.nn.functional.one_hot(target)\n",
    "target.shape\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1cde8-7e77-4198-bf79-9ddaea111032",
   "metadata": {},
   "source": [
    "### apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b3edcb-52c3-45e9-a9a5-aaed829f43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"text\"]  # this has n_rows which = batch_size\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "    # add labels\n",
    "    labels_batch = torch.tensor(examples['label'])\n",
    "    #torch.transpose(labels_batch, 0, 1)\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = torch.nn.functional.one_hot(labels_batch)\n",
    "    labels_matrix = labels_matrix.float()  # without converting int to float, you get an error later\n",
    "    # print(labels_matrix)\n",
    "    encoding[\"label\"] = labels_matrix#.tolist()\n",
    "  \n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fcb5b-3d12-49dd-b740-eda501eff7e3",
   "metadata": {},
   "source": [
    "#### encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e114fd5-9f54-4924-bb9d-c89668449bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7c7549cc574fc794893ea0e4633276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8860b3b2a0a4d09be61693377baaf94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize \n",
    "encoded_dataset = raw_dataset.map(preprocess_data, batched=True)\n",
    "encoded_dataset['test'][1]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e20076-2c72-40e3-95cb-6645fefd2561",
   "metadata": {},
   "source": [
    "##### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5df76d-ff62-42d8-aba5-af2ad149bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a, b = raw_dataset['test'].train_test_split(test_size=0.001).values()\n",
    "#del a\n",
    "#b_ = b.map(preprocess_data, batched=True)\n",
    "#b_['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b893d2-e623-40e9-9658-80ae81cad300",
   "metadata": {
    "tags": []
   },
   "source": [
    "### carve out a valid split\n",
    "different ways to create valid-test splits from train:\n",
    "1. random sampling: simply use random_split on torch.utils.data.Dataset object. It returns a torch.utils.data.Subset (subset of indices from parent dataset)\n",
    "2. use test_train_split from sklearn.model_selection()\n",
    "3. can also use weightedRandomSampler() https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22f7efee-44ed-4b7d-9da3-01275a080666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 1., 0.]), tensor([0., 0., 0., 1.])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 1900, 3: 1900, 1: 1900, 0: 1900})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describe_label_distr_from_data_loader(dl):\n",
    "    label_list = []\n",
    "    for idx, item in enumerate(dl):\n",
    "        batch_labels_onehot = item['label']#.tolist()\n",
    "        batch_labels = [torch.argmax(label_onehot).item() for label_onehot in batch_labels_onehot]\n",
    "        label_list.extend(batch_labels)\n",
    "    print(f'distribution of labels: {collections.Counter(label_list)}')\n",
    "\n",
    "# trial\n",
    "labels = [torch.tensor(instance['label']) for instance in encoded_dataset['test']]\n",
    "print(labels[:2])\n",
    "labels_ = [torch.argmax(label_onehot).item() for label_onehot in labels]\n",
    "collections.Counter(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2b535-47aa-416a-bb1d-c4a7ee9bc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this needed?\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b644386-9db7-4850-9863-3820cca41a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to create tratin/valid sets\n",
    "train_dataset, validation_dataset= encoded_dataset['train'].train_test_split(test_size=0.1).values()\n",
    "valid_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)#, collate_fn=data_collator)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)#, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d66476-be35-4313-8e49-ddb3e57759ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "describe_label_distr_from_data_loader(valid_loader)\n",
    "describe_label_distr_from_data_loader(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656622fb-9ad8-44e7-aa0d-01be63f398d8",
   "metadata": {},
   "source": [
    "3. simply from splitting the train dataset using pytorch internal wrapper on \n",
    "train_dataset, validation_dataset= encoded_dataset['train'].train_test_split(test_size=0.1).values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff102e16-a3f4-4254-b5d8-3be11316cd25",
   "metadata": {},
   "source": [
    "### tokenise, training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(GPT, \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(label2id),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d297ff8-8a79-4c71-b80d-6d7e3c5acb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(f\"data/models_20230606\")\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe326c-3ade-418f-b8e4-782ae6e24281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eed688-0c7d-405e-9ded-a43d0ecb7175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f03676-1dde-4145-8000-fe1033adf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e5c7e-e91f-4785-aba2-fe9064e408da",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=METRIC_NAME,\n",
    "    logging_dir='./logs',            # directory for storing logs*\n",
    "    logging_steps=20,\n",
    "    report_to='wandb'\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d963b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de9b1cfc-6f13-4830-8666-f4d080443ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e44f8-ae75-4635-8018-46526c3068b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/bioblp-env/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/llm_peft_exploration/wandb/run-20230606_182718-si4m4sz5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/discoverylab/huggingface/runs/si4m4sz5' target=\"_blank\">restful-energy-7</a></strong> to <a href='https://wandb.ai/discoverylab/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/discoverylab/huggingface' target=\"_blank\">https://wandb.ai/discoverylab/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/discoverylab/huggingface/runs/si4m4sz5' target=\"_blank\">https://wandb.ai/discoverylab/huggingface/runs/si4m4sz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='591' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 591/6750 1:34:30 < 16:28:18, 0.10 it/s, Epoch 0.17/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677d24c-070d-45da-8176-34778dbfe5cd",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "732fa338-df65-4127-bb5f-fe85be3f4373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0778539851307869,\n",
       " 'eval_f1': 0.9458218549127639,\n",
       " 'eval_roc_auc': 0.9633611111111112,\n",
       " 'eval_accuracy': 0.9409166666666666}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26ee8ebe-86f8-4187-87ef-c632a44e6be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08296191692352295,\n",
       " 'eval_f1': 0.9416106497957031,\n",
       " 'eval_roc_auc': 0.9605701754385965,\n",
       " 'eval_accuracy': 0.9361842105263158}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.eval_dataset=encoded_dataset['test']\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0abb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(prompt_model, 'data/models/tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c0717",
   "metadata": {},
   "source": [
    "test how the accuracy improves with batches of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fcc855-871d-474a-a013-d2fc74fe5a96",
   "metadata": {},
   "source": [
    "### experiment - sequential supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7381d-3cdb-42a7-8c04-1b1b0adecd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, 1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea50482-b74f-4174-9cfd-bc7320aeb6db",
   "metadata": {},
   "source": [
    "##### push model to hf hub\n",
    "\n",
    "(https://colab.research.google.com/drive/1U7SX7jNYsNQG5BY1xEQQHu48Pn6Vgnyt?usp=sharing#scrollTo=H5j5YJE2hK58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5544d343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5ee05875f940e8af9d802355ad8d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"your-username/model-name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-bioblp-env [Python]",
   "language": "python",
   "name": "conda-env-.conda-bioblp-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
